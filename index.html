<!DOCTYPE html>
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- HTML Meta Tags -->
  <title>SDS Bridge</title>
  <meta name="description" content="Score Distillation as a Bridge Between Image Distributions">

  <!-- Facebook Meta Tags -->
  <meta property="og:url" content="https://sds-bridge.github.io/">
  <meta property="og:type" content="website">
  <meta property="og:title" content="Score Distillation as a Bridge Between Image Distributions">
  <meta property="og:description" content="Score Distillation as a Bridge Between Image Distributions">
  <meta property="og:image" content="https://sds-bridge.github.io/image_assets/method2.png">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta property="twitter:domain" content="sds-bridge.github.io/">
  <meta property="twitter:url" content="https://sds-bridge.github.io/">
  <meta name="twitter:title" content="Score Distillation as a Bridge Between Image Distributions">
  <meta name="twitter:description" content="Score Distillation as a Bridge Between Image Distributions">
  <meta name="twitter:image" content="https://sds-bridge.github.io/image_assets/method2.png">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Aleo:ital,wght@0,100..900;1,100..900&family=Arvo:ital,wght@0,400;0,700;1,400;1,700&family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Playfair+Display:ital,wght@0,490;1,490&display=swap" rel="stylesheet">


  <!-- Google tag (gtag.js) -->
  <script async="" src="./assets/js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-9VZKE74FPW');
  </script>
  <title>Expressive Text-to-Image Generation with Rich Text</title>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="./assets/css" rel="stylesheet">
  <link rel="stylesheet" href="./assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="./assets/css/bulma.min.css">
  <link rel="stylesheet" href="./assets/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./assets/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./assets/css/tab_gallery.css">
  <!-- <link rel="stylesheet" href="./assets/css/fontawesome.all.min.css"> -->
  <link rel="stylesheet" href="./assets/css/academicons.min.css">
  <link rel="stylesheet" href="./assets/css/index.css">
  <link rel="stylesheet" href="./assets/css/juxtapose.css">
  <link rel="stylesheet" href="./assets/css/image_card_fader.css">
  <link rel="stylesheet" href="./assets/css/image_card_slider.css">

  <link href='https://fonts.googleapis.com/css?family=Monoton' rel='stylesheet'>
  <link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet'>
  <link href='https://fonts.googleapis.com/css?family=Akronim' rel='stylesheet'>
  <link href='https://fonts.googleapis.com/css?family=Inconsolata' rel='stylesheet'>
  <link href='https://fonts.googleapis.com/css?family=Sofia ' rel='stylesheet'>
  <link href='https://fonts.googleapis.com/css?family=VT323 ' rel='stylesheet'>
  <link href='https://fonts.googleapis.com/css?family=Playfair Display ' rel='stylesheet'>

</head>


<body data-new-gr-c-s-check-loaded="14.1098.0" data-gr-ext-installed="">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">Score Distillation as a Bridge Between Image Distributions</h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://mcallisterdavid.com/">David McAllister</a><sup>1</sup>&nbsp
              </span>
              <span class="author-block">
                <a href="https://songweige.github.io/">Songwei
                  Ge</a><sup>2</sup>&nbsp</span>
              <span class="author-block">
                <a href="https://jbhuang0604.github.io/">Jia-Bin
                  Huang</a><sup>2</sup>&nbsp
              </span>
              <span class="author-block">
                <a href="https://www.cs.umd.edu/~djacobs/">David
                  Jacobs</a><sup>2</sup>&nbsp</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://people.eecs.berkeley.edu/~efros/">
                  Alexei A. Efros</a><sup>1</sup>&nbsp
              </span>
              <span class="author-block">
                <a href="https://holynski.org/">
                  Aleksander Holynski</a><sup>1</sup>&nbsp
              </span>
              <span class="author-block">
                <a href="https://people.eecs.berkeley.edu/~kanazawa/">
                  Angjoo Kanazawa</a><sup>1</sup>&nbsp
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>UC Berkeley
                &nbsp</span>
              <span class="author-block"><sup>2</sup>University of Maryland, College Park &nbsp</span>
            </div>
            <br>
            <video id="dollyzoom" autoplay="" muted="" loop="" playsinline="" width="100%">
              <source src="./video_assets/teaser/website_teaserv2.mp4" type="video/mp4">
            </video>

            <!-- 
            <div class="is-size-5 publication-venue">
              ICCV 2023
            </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://rich-text-to-image.github.io/assets/rich_text_to_image_generation.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false"
                        data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 384 512" data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z">
                        </path>
                      </svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2304.06720" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/SongweiGe/rich-text-to-image"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false"
                        data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 496 512" data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
                        </path>
                      </svg>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/spaces/songweig/rich-text-to-image"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-edit"></i>
                    </span>
                    <span>Demo</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://rich-text-to-image.github.io/#bibtex"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-obp"></i>
                    </span>
                    <span>BibTex</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
        <!-- <div class="has-text-justified">
          <iframe width="960" height="540" src="https://www.youtube.com/embed/ihDbAUh0LXk?si=ASIzJd_Q2Tq1pwjq" 
          title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div> -->
      </div>
    </div>
  </section>

  <!-- Test Section -->

  <!-- <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-centered">
      <div class="container has-text-justified">
        <video id="dollyzoom" autoplay="" muted="" loop="" playsinline="" height="100%">
          <source src="./video_assets/teaser/website_teaserv1.mp4" type="video/mp4">
        </video>
      </div>
    </div>
    </div>
  </section> -->

  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered" id="div_livingroom" style="display: true;">
        <div class="column">
          <div class="container has-text-justified">
            <p>
              <span style="font-size:1.1em;">Score distillation sampling<sup><a href="https://dreamfusion3d.github.io/">1</a></sup> (SDS) has proven to be an important tool, enabling
                the use of large-scale diffusion priors for tasks operating in data-poor domains. SDS and its variants optimize parametric images, i.e., images produced by a model like NeRF, with a
                pre-trained diffusion model. Such a method is valuable because it is applicable across many data-poor domains, including 3D. <br><br></span>
                <span style="font-size:1.1em;"> SDS is known to suffer from several
                  significant artifacts, such as oversaturation and oversmoothing. We present an analytical framework for the SDS family of methods and a simple, efficient method to rectify these artifacts. <br><br></span>
              <br>
            </p>
          </div>
        </div>
        <div class="column">
          <div class="content">
            <video id="dollyzoom" autoplay="" muted="" loop="" playsinline="" height="100%">
              <source src="./video_assets/techfigure1/fig1_v3.mp4" type="video/mp4">
            </video>
            <div class="container has-text-centered" >
              <span style="font-size:0.85em;">SDS-like methods optimized images to the natural image manifold. We can compute this gradient on renders from random 3D viewpoints.</span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="hero-body" style="padding-inline: 200px;">
    <div class="container is-max-desktop">
      <div class="columns is-centered" id="div_livingroom" style="display: true;">
        <div class="column">
          <div class="content has-text-centered">
            <!-- <img src="./image_assets/filler_image.png" id="image_livingroom" width="99%"> -->
            <video id="dollyzoom" autoplay="" muted="" loop="" playsinline="" width="60%">
              <source src="./video_assets/fig2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column">
          <div class="container has-text-justified">
            <p>
              <span style="font-size:1.1em;"> We investigate the core issues with SDS by casting it as a Schrödinger Bridge (SB) problem, which finds the optimal
                transport between two distributions. Specifically, these optimal paths connect the current optimized image distribution (e.g., renderings from a NeRF) to a target distribution (e.g., text-conditioned
                natural image distribution).<br><br></span>
                <span style="font-size:1.1em;"> Together, these paths form an optimal map from specific samples in the
                  source distribution to corresponding samples in the target distribution.  In an optimization framework,
                  the difference between paired source and target samples, computed with an SB, can be used as a
                  gradient to update the source. <br><br></span>
              <br>
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-centered">
      <div class="container has-text-justified">
        <p>
          <span style="font-size:1.1em;"> Instead of training a model to solve this problem directly, we use pre-trained diffusion models to approximate the bridge. This way, we leverage the rich priors learned over their datasets. <br><br></span>
          <span style="font-size:1.1em;"> Dual Diffusion Implicit Bridges (DDIBs) compose a diffusion inversion and denoising process for solving image-to-image translation problems without requiring a paired image dataset. 
              Instead, DDIBs use two diffusion models trained on different domains. Analogously, we use one model with two different text conditions. <br><br></span>
              <div class="content has-text-centered">
                <img src="./image_assets/schrodinger-bridge.svg" id="image_livingroom" width="99%">
              </div>
              <span style="font-size:1.1em;"> We can build a DDIB by solving the forward (noising) PF-ODE to invert the source image to the latent distribution. </span>
            <p>\[dx = [f(\mathbf{x}, t)-\frac{1}{2}g^2(t)\nabla_{\mathbf{x}} \log p_t(\mathbf{x})] dt \]</p>
            <span style="font-size:1.1em;"> We can then sample the corresponding target image by solving the reverse (denoising) PF-ODE. This deterministic conversion between
              image and latent representations is crucial to establish dual diffusion implicit bridges. </span>
          <br>
        </p>
      </div>
    </div>
    </div>
  </section>

  <div class="hero-body" style="padding-inline: 260px;">
    <div class="columns is-centered" id="div_livingroom" style="display: true;">
      <div class="column">
        <div class="container has-text-justified">
          <p>
            <span style="font-size:1.1em;">The SDS family of methods can be view as per-iteration estimates of the DDIB.
              Suppose that \(\psi_{t^\prime, \text{src}}\) and \(\psi_{t^\prime, \text{tgt}}\) denote the paths obtained by solving the PF-ODE
              from \(t\) to \(0\), both starting from  \(\mathbf{x}_{\theta, t}\), such that \(\psi_{0, \text{src}} \in p_\text{src}\), 
              \(\psi_{0, \text{tgt}} \in p_\text{tgt}\), \(\psi_{t, \text{src}}=\psi_{t, \text{tgt}}=\mathbf{x}_{\theta, t}\) (simplify this language). 
              This forms a dual diffusion bridge from \(\psi_{0, \text{src}}\) to \(\psi_{0, \text{tgt}}\), with displacement:<br></span>
              <span style="font-size:1.1em;">  \[\Delta \mathbf{\epsilon}_\text{SBP}^* = \psi_{0, \text{tgt}} - \psi_{0, \text{src}}\] </span>
              <span style="font-size:1.1em;">  Fully simulating this bridge involves solving two PF-ODEs, which invokes dozens of neural function evaluations (NFEs) to estimate the gradient each iteration. 
                Instead, one can estimate each half of the bridge with a single-step prediction: </span>
              <span style="font-size:1.1em;">  \[\mathbf{\epsilon}_\text{SBP} = \mathbf{\epsilon}_{\phi, \text{tgt}}(\mathbf{x}_{\theta, t})-\mathbf{\epsilon}_{\phi, \text{src}}(\mathbf{x}_{\theta, t})\] 
                where we add noise \(\mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\) to the image \(x_{\theta}\) obtain a latent input for \(\mathbf{\epsilon}_{\phi}\) at timestep \(t\). 
                That is, \(\mathbf{x}_{\theta, t}=\alpha_t \mathbf{x}+\sigma_t \mathbf{\epsilon}\). 
                This estimate is subject to the following sources of errors.
              </span>
              <br><br>
              <ol style="font-size:1.1em;">
                <li>
                    <p>First-order approximation error. Instead of performing full PF-ODE simulations, the single-step noising and prediction are less accurate and can induce errors. Recent works ISM <a href="https://arxiv.org/abs/2311.11284">[3]</a> and SDI <a href="https://lukoianov.com/sdi/">[4]</a> can be interpreted as reducing this error with a multi-step simulation to obtain \(\mathbf{x}_{\theta, t}\)</p>
                </li>
                <br>
                <li>
                    <p>Source distribution mismatch. The dual diffusion bridge relies on \(\mathbf{\epsilon}_{\phi, \text{src}}\) accurately estimating the distribution of the current sample, \(x_{\theta}\). A series of works can be viewed as improving this error <a href="#your-link">[]</a> by computing more accurate \(\mathbf{\epsilon}_{\phi, \text{tgt}}\).</p>
                </li>
            </ol>
            <br>
          </p>
        </div>
      </div>
      <div class="column">
        <div class="content has-text-centered">
          <img src="./image_assets/method2.png" id="image_livingroom" width="99%">
        </div>
      </div>
    </div>
  </div>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-centered">

        <div class="container has-text-justified">
          <p>
            <span style="font-size:1.1em;"> Instead of training a model to solve this problem directly, we use pre-trained diffusion models to approximate the bridge. This way, we leverage the rich priors learned over their datasets. <br><br></span>
              <span style="font-size:1.1em;"> Dual Diffusion Implicit Bridges (DDIBs) compose a diffusion inversion and denoising process for solving image-to-image translation problems without requiring a paired image dataset. 
                Instead, DDIBs use two diffusion models trained on different domains. Analogously, we use one model with two different text conditions. <br><br></span>
            <br>
          </p>
        </div>
        <!-- row 2 -->
        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <div class="tab_container">
                <div id="juxtapose-embed1" data-startingposition="30%" data-animate="true" class="juxtapose">
                  <div class="jx-slider">
                    <div class="jx-handle " style="left: 54.53%;">
                      <div class="jx-arrow jx-left"></div>
                      <div class="jx-control">
                        <div class="jx-controller" tabindex="0" role="slider" aria-valuenow="50" aria-valuemin="0"
                          aria-valuemax="100"></div>
                      </div>
                      <div class="jx-arrow jx-right"></div>
                    </div>
                    <div class="jx-image jx-left " style="width: 54.53%;">
                      <img src="./image_assets/teaser/panda_plain.png" alt="" data-label="Plain-text">
                    </div>
                    <div class="jx-image jx-right " style="width: 45.47%;"><img src="./image_assets/teaser/panda_rich.png"
                        alt="" data-label="Rich-text">
                    </div>
                  </div>
                </div>
              </div>
            </div>
            <div class="has-text-justified">
              <p>
                <span style="font-family:roboto;">"A panda<sup>1</sup> standing on a cliff by a waterfall."</span>
              </p>
              <p>
                <span style="font-size:0.6em;"><sup>1</sup>Happy kung fu panda, asian art, ultra detailede.</span>
              </p>
            </div>
          </div>
          <div class="column">
            <div class="content">
              <div class="tab_container">
                <div id="juxtapose-embed1" data-startingposition="30%" data-animate="true" class="juxtapose">
                  <div class="jx-slider">
                    <div class="jx-handle " style="left: 54.53%;">
                      <div class="jx-arrow jx-left"></div>
                      <div class="jx-control">
                        <div class="jx-controller" tabindex="0" role="slider" aria-valuenow="50" aria-valuemin="0"
                          aria-valuemax="100"></div>
                      </div>
                      <div class="jx-arrow jx-right"></div>
                    </div>
                    <div class="jx-image jx-left " style="width: 54.53%;">
                      <img src="./image_assets/teaser/duck_plain.png" alt="" data-label="Plain-text">
                    </div>
                    <div class="jx-image jx-right " style="width: 45.47%;"><img
                        src="./image_assets/teaser/duck_rich.png" alt="" data-label="Rich-text">
                    </div>
                  </div>
                </div>
              </div>
            </div>
            <div class="has-text-justified">
              <p>
                <span style="font-family:roboto;">"A pixel art of a duck with a gun<sup>1</sup> in hand, wearing a hat<sup>2</sup>, minimalist, flat"</span>
              </p>
              <p>
                <span style="font-size:0.6em;"><sup>1</sup>A bouquet of flowers.</span><br>
                <span style="font-size:0.6em;"><sup>2</sup>A black hat decorated with a red flower.</span>
              </p>
            </div>
          </div>
          <div class="column">
            <div class="content">
              <div class="tab_container">
                <div id="juxtapose-embed2" data-startingposition="30%" data-animate="true" class="juxtapose">
                  <div class="jx-slider">
                    <div class="jx-handle " style="left: 54.53%;">
                      <div class="jx-arrow jx-left"></div>
                      <div class="jx-control">
                        <div class="jx-controller" tabindex="0" role="slider" aria-valuenow="50" aria-valuemin="0"
                          aria-valuemax="100"></div>
                      </div>
                      <div class="jx-arrow jx-right"></div>
                    </div>
                    <div class="jx-image jx-left " style="width: 54.53%;"><img
                        src="./image_assets/teaser/girl_plain.png" alt="" data-label="Plain-text">
                    </div>
                    <div class="jx-image jx-right " style="width: 45.47%;"><img
                        src="./image_assets/teaser/girl_rich.png" alt="" data-label="Rich-text">
                    </div>
                  </div>
                </div>
              </div>
            </div>
            <div class="has-text-justified">
              <p>
                <span style="font-family:roboto;">"A girl with <span style="color:rgb(255, 135, 0);">long hair</span> sitting in a cafe, by a table with coffee<sup>1</sup> on it, best quality, ultra detailed, dynamic pose."
              </p>
              <p>
                <span style="font-size:0.6em;"><sup>1</sup>Ceramic coffee cup with intricate design, a dance of earthy browns and delicate gold accents. The dark, velvety latte is in it.
                </span>
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <section class="section">

    <!--/ Matting. -->
    <div class="container is-max-desktop">

      <!-- color -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4 has-text-centered"><span style="color: #CD66FF;">F</span><span
              style="color: #FF6599;">o</span><span style="color: #FF0000;">n</span><span
              style="color: #FF8E00;">t</span> <span style="color: #f2f211;">c</span><span
              style="color: #008E00;">o</span><span style="color: #00C0C0;">l</span><span
              style="color: #400098;">o</span><span style="color: #8E008E;">r</span> controls the precise color of
            objects</h2>
          <div class="content has-text-centered">
            <img src="./image_assets/color_tri.png" width="150%">
          </div>
          <div class="content has-text-justified">
            <h4>
              Comparison with existing methods:
            </h4>
          </div>
          <div class="content has-text-centered">
            <img src="./image_assets/font_color.jpg" width="150%">
          </div>
        </div>
      </div>
      <!-- /color -->
      <hr>
      <!-- style -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4 has-text-centered"><span style="font-family:sofia;">Font style</span> indicates the
            styles of local regions</h2>
          <div class="content has-text-centered">
            <img src="./image_assets/font_tri.png" width="150%">
          </div>
          <div class="content has-text-justified">
            <h4>
              Comparison with existing methods:
            </h4>
          </div>
          <div class="content has-text-centered">
            <img src="./image_assets/font/font_sep-1.jpg" width="150%">
            <p class="has-text-centered">
              A small <u style="font-family:Monoton;">pond</u> (Ukiyo-e) surrounded by
              <u style="font-family:cursive;">skyscraper</u> (Cubism).
            </p>
            <img src="./image_assets/font/font_sep-3.jpg" width="150%">
            <p class="has-text-centered">
              A <u style="font-family:Akronim;">night sky filled with stars</u> (Van Gogh) above a <u
                style="font-family:Monoton;">turbulent sea with
                giant waves</u> (Ukiyo-e).
            </p>
          </div>
        </div>
      </div>
      <!-- /style -->
      <hr>
      <!-- footnote -->
      <h2 class="title is-4 has-text-centered">Footnote provides supplementary descriptions, enabling complex text
        prompts </h2>
      <div class="content has-text-centered">
        <img src="./image_assets/footnote_tri.png" width="150%">
      </div>
      <div class="content has-text-justified">
        <h4>
          Comparison with existing methods:
        </h4>
      </div>
      <ul class="nav nav-pills nav-justified" id="prompt-view-ul" style="width: 100%;margin-bottom: 0.5em;">
        <li style="font-size: 0.9em;" class="active"><a href="javascript: void(0);"
            onclick="ChangePrompt(0);">Livingroom</a>
        </li>
        <li style="font-size: 0.9em;" class=""><a href="javascript: void(0);" onclick="ChangePrompt(1);">Cityscape</a>
        </li>
      </ul>
      <ul class="nav nav-pills nav-justified" id="method-view-ul" style="width: 100%">
        <li style="font-size: 0.9em;" class="active"><a href="javascript: void(0);" onclick="ChangeMethod(0);">Ours</a>
        </li>
        <li style="font-size: 0.9em;" class=""><a href="javascript: void(0);" onclick="ChangeMethod(1);">Stable
            Diffusion [4] (Plain-Text)</a></li>
        <li style="font-size: 0.9em;" class=""><a href="javascript: void(0);" onclick="ChangeMethod(2);">Stable
            Diffusion [4] (Full-Text)</a></li>
        <li style="font-size: 0.9em;" class=""><a href="javascript: void(0);"
            onclick="ChangeMethod(3);">Attend-and-Excite
            [3]</a></li>
        <li style="font-size: 0.9em;" class=""><a href="javascript: void(0);" onclick="ChangeMethod(4);">InstructPix2Pix
            [2]</a></li>
        <li style="font-size: 0.9em;" class=""><a href="javascript: void(0);"
            onclick="ChangeMethod(5);">Prompt-to-Prompt
            [1]</a></li>
      </ul>
      <div class="columns is-centered" id="div_cityscape" style="display: none;">
        <div class="column">
          <div class="has-text-justified">
            <p>
              <span style="font-size:1.25em;">A car<sup><span style="color:red">1</span></sup> driving on the
                road. A bicycle<sup><span style="color:rgb(36, 192, 240)">2</span></sup> nearby a tree<sup><span
                    style="color:green">3</span></sup>. A cityscape<sup><span
                    style="color:rgb(238, 238, 62)">4</span></sup> in the background.<br><br></span>
              <span style="font-size:1.1em;"><sup><span style="color:red">1</span></sup>A sleek sports car gleams on the
                road in the sunlight, with its aerodynamic curves and polished finish catching the light.</span><br>
              <span style="font-size:1.1em;"><sup><span style="color:rgb(36, 192, 240)">2</span></sup>A bicycle with
                rusted frame and worn tires.</span><br>
              <span style="font-size:1.1em;"><sup><span style="color:green">3</span></sup>A dead tree with a few red
                apples on it.</span><br>
              <span style="font-size:1.1em;"><sup><span style="color:rgb(238, 238, 62)">4</span></sup>A bustling
                Hongkong cityscape with towering skyscrapers.</span>
            </p>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <img src="./image_assets/footnote/cityscape/cityscape_ours.jpg" id="image_cityscape" width="99%">
          </div>
        </div>
      </div>
      <div class="columns is-centered" id="div_livingroom" style="display: true;">
        <div class="column">
          <div class="has-text-justified">
            <p>
              <span style="font-size:1.25em;">A coffee table<sup><span style="color:red">1</span></sup> sits in front of
                a sofa<sup><span style="color:rgb(36, 192, 240)">2</span></sup> on a cozy carpet. A painting<sup><span
                    style="color:green">3</span></sup> on the wall. cinematic lighting, trending on artstation, 4k,
                hyperrealistic, focused, extreme details. <br><br></span>
              <span style="font-size:1.1em;"><sup><span style="color:red">1</span></sup>A rustic wooden coffee table
                adorned with scented candles and many books.</span><br>
              <span style="font-size:1.1em;"><sup><span style="color:rgb(36, 192, 240)">2</span></sup>A plush sofa with
                a soft blanket and colorful pillows on it. </span><br>
              <span style="font-size:1.1em;"><sup><span style="color:green">3</span></sup>A painting of wheat field
                with a cottage in the distance, close up shot, trending on artstation, cgsociety, hd, calm,
                complimentary colours, realistic lighting, by Albert Bierstadt, Frederic Edwin Church.</span><br>
            </p>
          </div>
        </div>
        <div class="column">
          <div class="content has-text-centered">
            <img src="./image_assets/footnote/livingroom/livingroom_ours.jpg" id="image_livingroom" width="99%">
          </div>
        </div>
      </div>
      <!-- /footnote -->
    </div>
  </section>

  <!-- Method & Workflow -->
  <section class="hero is-light">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-centered">
        <h2 class="title is-3">Rich-text-to-image Generation Framework</h2>
        <div class="has-text-justified">
          <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="./video_assets/framework.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <p>
            The plain text prompt is first input to the diffusion model to collect the self-attention and cross-attention maps. Attention
            maps are averaged across different heads, layers, and time steps. The self-attention maps are then used to create the segmentation
            using spectral clustering and the cross-attention label each segment. 
            The rich text prompts obtained from the editor are stored in JSON format,
            providing attributes for each token span. According to the attributes of each token, corresponding controls
            are applied as denoising prompt or guidance on the regions indicated by the token maps.
            We preserve the structure and background from plain-text generation by injecting the features or blending the noised samples.<br>
          </p>
        </div>
        <!-- <hr>
        <h2 class="title is-3">Example Workflow with our Framework</h2>
        <div class="has-text-justified">
          <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="./video_assets/workflow.mp4" type="video/mp4">
          </video>
        </div>
        Our framework can naturally be integrated into a rich text editor, enabling a tight, streamlined UI. -->
      </div>
    </div>
  </section>
  <!--/ Method & Workflow -->

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column is-full-width">
                <h2 class="title is-3 has-text-centered">References</h2>
                <div class="content has-text-justified">
                  <p>
                  </p>
                  [1] Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. <a
                    href="https://arxiv.org/abs/2208.01626">Prompt-to-prompt image editing with cross attention
                    control.</a> arXiv:2208.01626, 2022.<br>
                  [2] Tim Brooks, Aleksander Holynski, and Alexei A Efros. <a
                    href="https://arxiv.org/abs/2211.09800">Instructpix2pix: Learning to follow image editing
                    instructions.</a> CVPR, 2023<br>
                  [3] Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, and Daniel Cohen-Or. <a
                    href="https://arxiv.org/abs/2301.13826">Attend-and-excite: Attention-based semantic guidance for
                    text-to-image diffusion models.</a>arXiv preprint arXiv:2301.13826, 2023.<br>
                  [4] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. <a
                    href="https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html6">High-resolution
                    image synthesis with latent diffusion models.</a>CVPR, 2022<br>
                  <p></p>
                </div>
                <!-- Prompt Interpolation image -->
              </div>
            </div>

            <!-- Acknowledgements. -->
            <div class="columns is-centered">
              <div class="column is-full-width">
                <h2 class="title is-3 has-text-centered">Acknowledgment</h2>
                <div class="content has-text-justified">
                  <p>
                    We thank Mia Tang, Aaron Hertzmann, Nupur Kumari, Gaurav Parmar, Ruihan Gao, and Aniruddha Mahapatra
                    for their helpful discussion, code reviewing, and paper reading. We thank AK, Radamés Ajna, and
                    other HuggingFace team members for their help and support with our online demo. This work is partly
                    supported by NSF award no. 239076, NSF grants no. IIS-1910132 and IIS-2213335.
                  </p>
                </div>
              </div>
            </div>
            <!--/ Acknowledgements. -->

          </div>
        </div>
      </div>
    </div>
  </section>
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title"><a id="bibtex">BibTeX</a></h2>
      <pre><code>@inproceedings{ge2023expressive,
      title={Expressive Text-to-Image Generation with Rich Text},
      author={Ge, Songwei and Park, Taesung and Zhu, Jun-Yan and Huang, Jia-Bin},
      booktitle={IEEE International Conference on Computer Vision (ICCV)},
      year={2023}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>

  </footer>


  <script type="text/javascript">
    var currentMethodList = ['ours', 'plain', 'full', 'aae', 'ip2p', 'p2p'];
    var currentMethod = "ours";

    function ChangeMethod(idx) {
      var li_list = document.getElementById("method-view-ul").children;
      for (i = 0; i < li_list.length; i++) {
        li_list[i].className = "nav-link";
      }
      li_list[idx].className = "nav-link active";
      currentMethod = currentMethodList[idx];

      var image_livingroom = document.getElementById('image_livingroom');
      var image_cityscape = document.getElementById('image_cityscape');
      image_livingroom.src = "./image_assets/footnote/livingroom/livingroom_" + currentMethod + ".jpg";
      image_cityscape.src = "./image_assets/footnote/cityscape/cityscape_" + currentMethod + ".jpg";
    }
    function ChangePrompt(idx) {
      var li_list = document.getElementById("prompt-view-ul").children;
      for (i = 0; i < li_list.length; i++) {
        li_list[i].className = "nav-link";
      }
      li_list[idx].className = "nav-link active";
      var div_livingroom = document.getElementById('div_livingroom');
      var div_cityscape = document.getElementById('div_cityscape');
      if (idx == 0) {
        div_livingroom.style.display = "";
        div_cityscape.style.display = "none";
      } else {
        div_livingroom.style.display = "none";
        div_cityscape.style.display = "";
      }
    }
  </script>

  <script src="./assets/js/juxtapose.js"></script>
  <script src="./assets/js/popper.min.js"></script>
  <script src="./assets/js/jquery.min.js"></script>
  <script src="./assets/js/bootstrap.min.js"></script>
  <script defer="" src="./assets/js/fontawesome.all.min.js"></script>
  <script src="./assets/js/bulma-carousel.min.js"></script>
  <script src="./assets/js/bulma-slider.min.js"></script>
  <script src="./assets/js/magnifier.js"></script>

</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration>

</html>